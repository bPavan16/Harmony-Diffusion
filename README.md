# 🎶 Harmony-Diffusion : Text-to-Music Generation with Diffusion Models

text-to-music is a research-oriented NLP course project (6th Sem) that explores generating music directly from natural language prompts using a **Diffusion-based generative model**, trained on the **MusicCaps dataset**. It leverages the power of **PyTorch** and recent advancements in text-conditioned generative modeling to bridge the gap between natural language and audio generation.

---

## ✨ Highlights

- 🧠 **Diffusion-based architecture** for music synthesis
- 📝 **Text-prompt conditioning** using captions from MusicCaps
- 🎧 Generates raw waveform or mel spectrogram outputs
- 🔬 Built in **PyTorch** for research flexibility
- 📚 Uses [Google's MusicCaps dataset](https://github.com/google-research/google-research/tree/master/musiccaps)

---

