# ğŸ¶ Harmony-Diffusion : Text-to-Music Generation with Diffusion Models

text-to-music is a research-oriented NLP course project (6th Sem) that explores generating music directly from natural language prompts using a **Diffusion-based generative model**, trained on the **MusicCaps dataset**. It leverages the power of **PyTorch** and recent advancements in text-conditioned generative modeling to bridge the gap between natural language and audio generation.

---

## âœ¨ Highlights

- ğŸ§  **Diffusion-based architecture** for music synthesis
- ğŸ“ **Text-prompt conditioning** using captions from MusicCaps
- ğŸ§ Generates raw waveform or mel spectrogram outputs
- ğŸ”¬ Built in **PyTorch** for research flexibility
- ğŸ“š Uses [Google's MusicCaps dataset](https://github.com/google-research/google-research/tree/master/musiccaps)

---

